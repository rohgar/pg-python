{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8715cc7-39d1-46f7-a931-07a6aead36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f8c25-bfde-429b-a63a-c7c48c8f38d9",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290fd4bc-a66c-4e76-b5a5-3fc61a8f9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved CSV files\n",
    "# data_csv_file = '/Users/rohit24/Projects/meta/full_data.csv'\n",
    "\n",
    "# df = pd.read_csv(data_csv_file)\n",
    "\n",
    "# label_2_id = {\"__label__aggregate\": 0, \"__label__model_fields\": 1, \"__label__non_aggregate_or_model_data\": 2}\n",
    "# id_2_label = [\"__label__aggregate\", \"__label__model_fields\", \"__label__non_aggregate_or_model_data\"]\n",
    "# df['label'] = df['target_label'].map(label_2_id)\n",
    "# df.drop(columns=['target_label'], inplace=True)\n",
    "# df.head(5)\n",
    "\n",
    "# texts = df['combined_field_name_and_description']\n",
    "# labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61970f64-bcfc-4852-b289-b23811e6d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_file = '/Users/rohit24/Projects/rohit/pgpython/src/fast_text/data/IMDB_dataset_100.csv'\n",
    "\n",
    "df = pd.read_csv(data_csv_file)\n",
    "texts = df['review'].tolist()\n",
    "labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2d665-338f-4aa9-8a66-b2a8bc41c4bf",
   "metadata": {},
   "source": [
    "# Bert\n",
    "Ref: https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f7ca99-103a-40d6-b6e9-f3f87902c302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohit24/.venv/jupyter/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup # AdamW deprecated\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e229c9-1447-4f81-8760-91557a7c94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self.texts):\n",
    "            raise IndexError(f\"Index {idx} out of range (dataset size: {len(self.texts)})\")\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7640e10e-5588-4ebb-9f49-07d152e721f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724577d1-d41f-4cae-bd65-c30d47ea4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d17345b-51f9-43fe-a8e6-5d170d5cdc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464982e1-5382-4daf-9600-aa5ceb91a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return \"positive\" if preds.item() == 1 else \"negative\"\n",
    "        # return id_2_label[preds.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e76f71c-9e46-4026-acd8-422e53ca45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2069539-f331-4c92-8f6a-9590158707b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150d7500-5de2-4c9b-b65f-f9dbe32d42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0696d25-7cf8-45e8-99cd-68993cbef326",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7528de42-62a0-4296-a1e8-c73eb5a4ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb4f557-916c-44e6-ad44-1eaefe947a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Validation Accuracy: 0.3000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42         9\n",
      "           1       0.20      0.09      0.12        11\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.27      0.32      0.27        20\n",
      "weighted avg       0.26      0.30      0.26        20\n",
      "\n",
      "Epoch 2/4\n",
      "Validation Accuracy: 0.3000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42         9\n",
      "           1       0.20      0.09      0.12        11\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.27      0.32      0.27        20\n",
      "weighted avg       0.26      0.30      0.26        20\n",
      "\n",
      "Epoch 3/4\n",
      "Validation Accuracy: 0.3000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42         9\n",
      "           1       0.20      0.09      0.12        11\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.27      0.32      0.27        20\n",
      "weighted avg       0.26      0.30      0.26        20\n",
      "\n",
      "Epoch 4/4\n",
      "Validation Accuracy: 0.3000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42         9\n",
      "           1       0.20      0.09      0.12        11\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.27      0.32      0.27        20\n",
      "weighted avg       0.26      0.30      0.26        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a352ee-2dce-424c-9676-66e6e23c07f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: The movie was great and I really enjoyed the performances of the actors.\n",
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
    "print(f\"Query text: {test_text}\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3f15a-778d-4fdc-809b-c27f36c98b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
